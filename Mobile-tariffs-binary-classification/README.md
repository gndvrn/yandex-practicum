
<p>Based on subscriber data for a certain period, several classification models were built, whose metrics were compared and the most suitable model was identified, which shows accuracy in predictions of more than <b><tt>80%</tt></b>, which is higher than the minimum required value of <tt>75%</tt>.</p><h3>Brief summary of completed tasks</h3><h4>Step 1. Data Overview</h4><ul><li>The necessary libraries for research were imported</li><li>Data was loaded and read, alternative ways of obtaining source data were provided</li><li>Information about the data was evaluated</li><li>Data types were changed where necessary, and data was checked for explicit duplicates</li></ul><h4>Step 2. Data Splitting</h4><ul><li>The source data was divided into three sets: training, validation, and test, in a ratio of 3:1:1, respectively</li><li>Each of the datasets was locally saved</li></ul><h4>Step 3. Model Selection</h4><ul><li>The following models were considered as candidates for the best model:<ul><li><b><tt>LogisticRegression</tt></b></li><li><b><tt>RandomForestClassifier</tt></b></li></ul></li><li>For each model, <em>K-fold cross-validation</em> was performed and optimal hyperparameters were selected using <tt>GridSearchCV</tt>. Additionally, the three best models in each class were compared and the best one was selected from them.</li><li>Observations were made for each model based on the resulting metric values:<ul><li><tt>Accuracy</tt></li><li><tt>Precision</tt></li><li><tt>Recall</tt></li><li><tt>F1-score</tt></li></ul></li></ul><h4>Step 4. Model Testing on the Test Set</h4><ul><li>The models with optimal hyperparameters from each category were tested on the test data</li><li>Observations were described, and the <b><tt>RandomForestClassifier</tt></b> model was selected.</li></ul>
<h4>Step 5. Checking the Model for Adequacy</h4><ul><li>The value of the <tt>Accuracy</tt> metric of the selected <b><tt>RandomForestClassifier</tt></b> model was compared with the value of the same metric of the <b><tt>DummyClassifier</tt></b> model. The model turned out to be adequate.</li></ul>
<h3>How to use the obtained result in business? How to make money on these predictions?</h3><p>After obtaining results that meet the technical specifications (in our case, it was required to achieve a minimum accuracy of 75%), personally, I would work on presenting them in the form of, for example, a presentation, which I would then show to sales managers.</p><p>It would be reasonable to include graphs in it that would visualize the dynamics of sales growth after implementing my algorithm.</p><p>If the growth is significant, then I would propose considering the possibility of implementing my algorithm into the existing recommendation system.</p><p><strong>The main thing I wanted to convey</strong>: the algorithm will allow targeting the purchasing power of those customers who really do not understand why it is worth overpaying for a better tariff, and if expanding in this direction, the recommendation system will be able to select the optimal tariff for the client, and the mobile operator will make some money for this convenience.</p><h3>What could lead to incomplete results?</h3><ul><li>Small data volume. Because of this, the models were prone to underfitting, which negatively affects metric values.</li><li>Small number of features. As it was found, logistic regression models are difficult to classify objects when there are few truly significant features.</li></ul>

</div>